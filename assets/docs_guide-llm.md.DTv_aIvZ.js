import{_ as t,c as a,o,a5 as s,dX as i,dY as r,dZ as l,d_ as p,d$ as n,e0 as d,e1 as c,e2 as m}from"./chunks/framework.B0NrSsnP.js";const w=JSON.parse('{"title":"AI Automatic Typesetting","description":"","frontmatter":{"title":"AI Automatic Typesetting"},"headers":[],"relativePath":"docs/guide-llm.md","filePath":"docs/guide-llm.md","lastUpdated":1762421473000}'),u={name:"docs/guide-llm.md"};function h(g,e,b,_,f,y){return o(),a("div",null,[...e[0]||(e[0]=[s('<h1 id="ai-features" tabindex="-1">AI Features <a class="header-anchor" href="#ai-features" aria-label="Permalink to “AI Features”">​</a></h1><h2 id="text-math-and-tables-as-prompts" tabindex="-1">Text, Math, and Tables as prompts! <a class="header-anchor" href="#text-math-and-tables-as-prompts" aria-label="Permalink to “Text, Math, and Tables as prompts!”">​</a></h2><p>Import LLM blocks as shown below:</p><p><img src="'+i+'" alt=""></p><p>While most LLMs only accept plain text prompts, Liii STEM accepts all types of texts as prompts!</p><blockquote><p>In the figure below, the blue portion denotes the user&#39;s input, and the remainder constitutes the output of the large model.</p></blockquote><ol><li>The LLM &#39;s dialogue interface supports mathematical formulas, as shown in the picture below:</li></ol><p><img src="'+r+'" alt=""></p><ol start="2"><li>Table as prompt!:</li></ol><p><img src="'+l+'" alt=""></p><h2 id="ocr-handwritten-recognition" tabindex="-1">OCR &amp; Handwritten Recognition <a class="header-anchor" href="#ocr-handwritten-recognition" aria-label="Permalink to “OCR &amp; Handwritten Recognition”">​</a></h2><p>Specifically, Liii STEM recognizes images—even your handwritten formulas!</p><p>How to use:</p><p>Paste an image directly as a prompt or insert it via the menu bar. Press <code>Enter</code> to run. (You add more prompts on a new line by pressing <code>Shift+Enter</code>)</p><p><img src="'+p+'" alt=""></p><ul><li><strong>Notes</strong>: Among the LLMs listed, only the OCR model accepts images as prompts.</li></ul><p><img src="'+n+'" alt=""></p><blockquote><p>Image processing with the large model may take some time. Please be patient.</p></blockquote><h2 id="editable-model-output" tabindex="-1">Editable Model Output <a class="header-anchor" href="#editable-model-output" aria-label="Permalink to “Editable Model Output”">​</a></h2><p>The outputs of LLMs are unmodifiable in most cases. However, the output generated by Liii STEM&#39;s built-in LLMs can be directly edited by Liii STEM!</p><p><img src="'+d+'" alt=""></p><h2 id="system-prompts-and-file-reading" tabindex="-1">System Prompts and File Reading <a class="header-anchor" href="#system-prompts-and-file-reading" aria-label="Permalink to “System Prompts and File Reading”">​</a></h2><p>If you have specific requirements regarding the role, response style, or behavioral guidelines of LLMs during a conversation, you can set a system prompt after entering the chat interface. Here’s how:</p><p>Use the keyword <code>%system</code> followed by your custom prompt. For example:<code>%system YOUR_SYSTEM_PROMPT</code></p><p><img src="'+c+'" alt=""></p><p>Also, use the keyword <code>%include</code> followed by the file path:<code>%include /path/to/your/file</code> to read files.</p><p>For example:</p><p><img src="'+m+'" alt=""></p><blockquote><p>Only plain text file types are supported, such as <code>.txt</code>, <code>.tex</code>, and <code>.md</code>.</p></blockquote>',29)])])}const x=t(u,[["render",h]]);export{w as __pageData,x as default};
